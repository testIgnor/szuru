{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import pyszuru\n",
    "import glob\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from requests.exceptions import ConnectTimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = os.getenv('USER')\n",
    "PASS = os.getenv('PASS')\n",
    "LINK = os.getenv('LINK')\n",
    "mybooru = pyszuru.API(\n",
    "    LINK,\n",
    "    username=USER,\n",
    "    password=PASS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_tagset(txtfile):\n",
    "    with open(txtfile, 'r') as tx:\n",
    "        tagset = set([ x.strip().replace('**', ',').split(',')[0].lower() for x in tx.read().splitlines() ])\n",
    "    return tagset\n",
    "\n",
    "def charfile_to_tagset(txtfile):\n",
    "    with open(txtfile, 'r') as tx:\n",
    "        pattern = re.compile('\\((.*?):\\d.\\d\\)')\n",
    "        tagset = []\n",
    "        for line in tx.read().splitlines():\n",
    "            x = line.replace('[', '').replace(']', '')\n",
    "            if pattern.findall(x):\n",
    "                tagset.append(pattern.findall(x)[0].strip().lower())\n",
    "            else:\n",
    "                print(f'Problem in file {txtfile}! Offending line is:')\n",
    "                print(line)\n",
    "        tagset = set(tagset)\n",
    "    return tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "donepath = \"../done/\"\n",
    "files = glob.glob(\"../tmp/*.png\")\n",
    "char_files = glob.glob(\"E:/stable-diffusion-webui/extensions/Umi-AI-Embeds/wildcards/characters/*.txt\") + glob.glob(\"E:/stable-diffusion-webui/extensions/Umi-AI-Embeds/wildcards/characters/*.tags\") + [\"E:/stable-diffusion-webui/extensions/Umi-AI-Embeds/wildcards/Franchise Girls.txt\"]\n",
    "species_files = glob.glob(\"E:/stable-diffusion-webui/extensions/Umi-AI-Embeds/wildcards/species/*.txt\")\n",
    "comm_file = \"E:/stable-diffusion-webui/extensions/Umi-AI-Embeds/wildcards/Common Tags.txt\"\n",
    "\n",
    "characters = set()\n",
    "for cfile in char_files:\n",
    "    characters = characters.union( charfile_to_tagset(cfile) )\n",
    "\n",
    "species = set()\n",
    "for sfile in species_files:\n",
    "    species = species.union( charfile_to_tagset(sfile) )\n",
    "common_tags = txt_to_tagset(comm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(im):\n",
    "    parameters = im.info['parameters']\n",
    "    tokens = []\n",
    "    ctags = []\n",
    "    for line in parameters.splitlines()[:-2]:\n",
    "        for sub in line.split(\",\"):\n",
    "            matches = re.findall(r'\\((.*?):\\d.\\d\\)', sub)\n",
    "            if matches:\n",
    "                tokens += [match.strip().lower() for match in matches]\n",
    "        ctags += [ x.strip().lower() for x in line.replace('(', ' ').replace(')', ', ').replace(':', ', ').lower().split(',') ]\n",
    "    tokens = set(tokens)\n",
    "    ctags = set(ctags)\n",
    "\n",
    "    character_tags = [ x.replace('\\\\', '').replace(' ', '_') for x in tokens.intersection(characters)]\n",
    "    species_tags = [ x.replace('\\\\', '').replace(' ', '_') for x in tokens.intersection(species)]\n",
    "    comm_tags = [ x.replace(' ', '_') for x in common_tags.intersection(ctags) ]\n",
    "\n",
    "    return character_tags, species_tags, comm_tags\n",
    "\n",
    "def upload_file(\n",
    "                f, character_tags, species_tags, comm_tags,\n",
    "                update_posts=True, sleep_time=30, updated=0, skipped=0, new_tags = []\n",
    "                ):\n",
    "    local_updated = updated\n",
    "    local_skipped = skipped\n",
    "    try:\n",
    "        with open(f, \"rb\") as to_upload:\n",
    "                file_token = mybooru.upload_file(to_upload)\n",
    "\n",
    "        print(f'Attempting to upload file {f}')\n",
    "        print(f'With tags {character_tags + species_tags + comm_tags}')\n",
    "        try:\n",
    "            new_post = mybooru.createPost(file_token, \"safe\")\n",
    "        except pyszuru.SzurubooruHTTPError as e:\n",
    "            print(e)\n",
    "            if 'PostAlreadyUploadedError' in str(e):\n",
    "                print(\"For file \", f)\n",
    "                if update_posts:\n",
    "                    post_id = re.split('\\(|\\)', str(e) )[1]\n",
    "                    print('Will try to update tags...')\n",
    "                    new_post = mybooru.getPost(post_id)\n",
    "                    local_updated += 1\n",
    "                else:\n",
    "                    print('Skipping...')\n",
    "                    local_skipped += 1\n",
    "                    return local_updated, local_skipped, []\n",
    "        for tag in character_tags:\n",
    "            try:\n",
    "                new_post.tags = [tag]\n",
    "            except pyszuru.SzurubooruHTTPError as e:\n",
    "                print(e)\n",
    "                if 'TagNotFoundError' in str(e):\n",
    "                    if tag in str(e):\n",
    "                        new_tag = mybooru.createTag(tag)\n",
    "                        new_tag.category = 'character'\n",
    "                        new_tag.push()\n",
    "                        new_tags.append(tag)\n",
    "                        print(f'Created tag {tag}')\n",
    "        for tag in species_tags:\n",
    "            try:\n",
    "                new_post.tags = [tag]\n",
    "            except pyszuru.SzurubooruHTTPError as e:\n",
    "                print(e)\n",
    "                if 'TagNotFoundError' in str(e):\n",
    "                    if tag in str(e):\n",
    "                        new_tag = mybooru.createTag(tag)\n",
    "                        new_tag.category = 'species'\n",
    "                        new_tag.push()\n",
    "                        new_tags.append(tag)\n",
    "                        print(f'Created tag {tag}')\n",
    "        for tag in comm_tags:\n",
    "            try:\n",
    "                new_post.tags = [tag]\n",
    "            except pyszuru.SzurubooruHTTPError as e:\n",
    "                print(e)\n",
    "                if 'TagNotFoundError' in str(e):\n",
    "                    if tag in str(e):\n",
    "                        new_tag = mybooru.createTag(tag)\n",
    "                        new_tag.push()\n",
    "                        new_tags.append(tag)\n",
    "                        print(f'Created tag {tag}')\n",
    "\n",
    "        new_post.tags = character_tags + species_tags + comm_tags\n",
    "        new_post.push()\n",
    "\n",
    "        print(f'Successfully uploaded file {f}')\n",
    "        print(f'With tags {character_tags + species_tags + comm_tags}')\n",
    "        return local_updated, local_skipped, new_tags\n",
    "    except pyszuru.SzurubooruHTTPError as e:\n",
    "        print(e)\n",
    "        err_msg = \"Failed to connect to szurubooru REST API\"\n",
    "        if err_msg in str(e):\n",
    "            print(f'Timed out! Will wait for {sleep_time}s and try again...')\n",
    "            time.sleep(sleep_time)\n",
    "            local_updated, local_skipped, new_tags = upload_file(\n",
    "                f, character_tags, species_tags, comm_tags,\n",
    "                update_posts=update_posts, updated=local_updated, skipped=local_skipped, new_tags=new_tags\n",
    "            )\n",
    "            return local_updated, local_skipped, new_tags\n",
    "        else:\n",
    "            raise Exception(e)\n",
    "    except ConnectTimeout as e:\n",
    "        print(e)\n",
    "        err_msg = \"Max retries exceeded with url\"\n",
    "        if err_msg in str(e):\n",
    "            print(f'Timed out! Will wait for {sleep_time}s and try again...')\n",
    "            time.sleep(sleep_time)\n",
    "            local_updated, local_skipped, new_tags = upload_file(\n",
    "                f, character_tags, species_tags, comm_tags,\n",
    "                update_posts=update_posts, updated=local_updated, skipped=local_skipped, new_tags=new_tags\n",
    "            )\n",
    "            return local_updated, local_skipped, new_tags\n",
    "        else:\n",
    "            raise Exception(e)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        err_msg = \"ConnectionResetError\"\n",
    "        if err_msg in str(e):\n",
    "            print(f'Timed out! Will wait for {sleep_time}s and try again...')\n",
    "            time.sleep(sleep_time)\n",
    "            local_updated, local_skipped, new_tags = upload_file(\n",
    "                f, character_tags, species_tags, comm_tags,\n",
    "                update_posts=update_posts, updated=local_updated, skipped=local_skipped, new_tags=new_tags\n",
    "            )\n",
    "            return local_updated, local_skipped, new_tags\n",
    "        else:\n",
    "            raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 0 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3265a389382b4a32b72f82fbaef7e2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images with 0 reprocessed and 0 rejections.\n"
     ]
    }
   ],
   "source": [
    "update_posts = False\n",
    "\n",
    "updated = 0\n",
    "skipped = 0\n",
    "new_tags = []\n",
    "print(f'Going to process {len(files)} images...')\n",
    "for f in tqdm(files):\n",
    "    with Image.open(f) as im:\n",
    "        character_tags, species_tags, comm_tags = extract_tags(im)\n",
    "\n",
    "    if ( len(character_tags) + len(comm_tags) + len(species_tags) ) == 0:\n",
    "        print(\"Warning! Could not auto detect tags\")\n",
    "        print(f\"for image {f}\")\n",
    "        print('Skipping...')\n",
    "        skipped += 1\n",
    "        continue\n",
    "    updated, skipped, new_tags = upload_file(\n",
    "        f, character_tags, species_tags, comm_tags,\n",
    "        update_posts=update_posts, updated=updated, new_tags=new_tags\n",
    "        )\n",
    "    os.replace(f, donepath + os.path.basename(f))\n",
    "\n",
    "print(f'Processed {len(files)} images with {updated} reprocessed and {skipped} rejections.')\n",
    "if len(new_tags) != 0:\n",
    "    print(f'Created new tags {new_tags}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abdb4dc8e184b008e24b7d0fd6d064f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flist = glob.glob(\"../to_upload/**/*.*\", recursive=True)\n",
    "for f in tqdm(flist):\n",
    "    print(f\"trying to upload {f}\")\n",
    "    if os.path.isfile(os.path.abspath(f)):\n",
    "        if (os.path.getsize(os.path.abspath(f)) / 1048576) > 1000:\n",
    "            print(f\"{f} is too large. skipping...\")\n",
    "            continue\n",
    "        updated, skipped, new_tags = upload_file(\n",
    "            f, [], [], [], update_posts=False\n",
    "            )\n",
    "        os.replace(f, donepath + os.path.basename(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
